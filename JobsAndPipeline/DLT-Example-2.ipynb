{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6e8830e1-f2f4-4538-b589-f4dc04df40b1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Create DLT with PySpark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9b413f29-bc96-45c7-8199-eb7d8cf63014",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Ingest data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0aa4b3c1-2847-4f25-95ed-7694968eddca",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sh\n",
    "rm -r /dbfs/device_stream\n",
    "mkdir /dbfs/device_stream\n",
    "wget -O /dbfs/device_stream/device_data1.csv https://github.com/MicrosoftLearning/mslearn-databricks/raw/main/data/device_data.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9eec458f-4f4f-4b0f-bad3-1a975bcfee7f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Use delta tables for streaming data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bce6e8c6-780f-4659-a995-b9212004f3dc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "# Define the schema for the incoming data\n",
    "schema = StructType([\n",
    "    StructField(\"device_id\", StringType(), True),\n",
    "    StructField(\"timestamp\", TimestampType(), True),\n",
    "    StructField(\"temperature\", DoubleType(), True),\n",
    "    StructField(\"humidity\", DoubleType(), True)\n",
    "])\n",
    "\n",
    "# Read streaming data from folder\n",
    "inputPath = '/device_stream/'\n",
    "iotstream = spark.readStream.schema(schema).option(\"header\", \"true\").csv(inputPath)\n",
    "print(\"Source stream created...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cd34b8ff-ec61-4b17-abd4-82b759f56db6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Write the data to a Delta table\n",
    "query = (iotstream\n",
    "        .writeStream\n",
    "        .format(\"delta\")\n",
    "        .option(\"checkpointLocation\", \"/tmp/checkpoints/iot_data\")\n",
    "        .start(\"/tmp/delta/iot_data\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "672946bd-dff8-4488-8495-074062c37353",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Create a Delta Live Table Pipeline\n",
    "A pipeline is the main unit for configuring and running data processing workflows with Delta Live Tables. It links data sources to target datasets through a Directed Acyclic Graph (DAG) declared in Python or SQL.\n",
    "\n",
    "1. Select **Jobs & Pipeline** in the left sidebar and then select **Create ETL Pipeline**.\n",
    "1. In the Create pipeline page, create a new pipeline with the following settings:\n",
    "    - **Pipeline name:** Ingestion Pipeline\n",
    "    - **Product edition:** Advanced\n",
    "    - **Pipeline mode:** Triggered\n",
    "    - **Source code:** Leave blank\n",
    "    - **Storage options:** Hive Metastore\n",
    "    - **Storage location:** dbfs:/pipelines/device_stream\n",
    "    - **Target schema:** default\n",
    "    - Cluster mode: **Fixed size**\n",
    "    - Workers: **0**\n",
    "    - Driver type: **Ds3v2**\n",
    "    - Click Create\n",
    "1. Select Create to create the pipeline (which will also create a blank notebook for the pipeline code).\n",
    "1. Once the pipeline is created, open the link to the blank notebook under Source code in the right-side panel. This opens the notebook in a new browser tab.\n",
    "1. In the first cell of the blank notebook, enter (but donâ€™t run) the following code to create Delta Live Tables and transform the data:\n",
    "\n",
    "<pre>\n",
    "import dlt\n",
    "from pyspark.sql.functions import col, current_timestamp\n",
    "    \n",
    "@dlt.table(\n",
    "    name=\"raw_iot_data\",\n",
    "    comment=\"Raw IoT device data\"\n",
    ")\n",
    "def raw_iot_data():\n",
    "    return spark.readStream.format(\"delta\").load(\"/tmp/delta/iot_data\")\n",
    "\n",
    "@dlt.table(\n",
    "    name=\"transformed_iot_data\",\n",
    "    comment=\"Transformed IoT device data with derived metrics\"\n",
    ")\n",
    "def transformed_iot_data():\n",
    "    return (\n",
    "        dlt.read(\"raw_iot_data\")\n",
    "        .withColumn(\"temperature_fahrenheit\", col(\"temperature\") * 9/5 + 32)\n",
    "        .withColumn(\"humidity_percentage\", col(\"humidity\") * 100)\n",
    "        .withColumn(\"event_time\", current_timestamp())\n",
    "    )\n",
    "</pre>\n",
    "\n",
    "4. Close the browser tab containing the notebook (the contents are automatically saved) and return to the pipeline. Then select Start."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "34afcf71-6eba-446f-aa64-c58e55824ccc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "5. After the pipeline has successfully completed, run the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2390c7e7-ff94-4582-90bd-4d0b7668c42e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SHOW TABLES;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "83d2223b-6c5b-42ad-afe7-c077849ba7fa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### View results as a visualization\n",
    "1. Run the following code to load the transformed_iot_data into a dataframe.\n",
    "1. From the output select + and then select Visualization to view the visualization editor, and then apply the following options:\n",
    "    - Visualization type: Line\n",
    "    - X Column: timestamp\n",
    "    - Y Column: Add a new column and select temperature_fahrenheit. Apply the Sum aggregation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1042a15e-ec82-43df-9fd0-4da90a4e9e75",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Databricks visualization. Run in Databricks to view."
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1.subcommand+json": {
       "baseErrorDetails": null,
       "bindings": {},
       "collapsed": false,
       "command": "%sql WITH q AS (SELECT * FROM transformed_iot_data) SELECT `timestamp`,SUM(`temperature_fahrenheit`) `column_75fe649f390` FROM q GROUP BY `timestamp`",
       "commandTitle": "Visualization 1",
       "commandType": "auto",
       "commandVersion": 0,
       "commentThread": [],
       "commentsVisible": false,
       "contentSha256Hex": null,
       "customPlotOptions": {
        "redashChart": [
         {
          "key": "type",
          "value": "CHART"
         },
         {
          "key": "options",
          "value": {
           "alignYAxesAtZero": true,
           "coefficient": 1,
           "columnConfigurationMap": {
            "x": {
             "column": "timestamp",
             "id": "column_75fe649f387"
            },
            "y": [
             {
              "column": "temperature_fahrenheit",
              "id": "column_75fe649f390",
              "transform": "SUM"
             }
            ]
           },
           "dateTimeFormat": "DD/MM/YYYY HH:mm",
           "direction": {
            "type": "counterclockwise"
           },
           "error_y": {
            "type": "data",
            "visible": true
           },
           "globalSeriesType": "line",
           "isAggregationOn": true,
           "legend": {
            "traceorder": "normal"
           },
           "missingValuesAsZero": true,
           "numberFormat": "0,0.[00000]",
           "percentFormat": "0[.]00%",
           "series": {
            "error_y": {
             "type": "data",
             "visible": true
            },
            "stacking": null
           },
           "seriesOptions": {
            "column_75fe649f390": {
             "type": "line",
             "yAxis": 0
            }
           },
           "showDataLabels": false,
           "sizemode": "diameter",
           "sortX": true,
           "sortY": true,
           "swappedAxes": false,
           "textFormat": "",
           "useAggregationsUi": true,
           "valuesOptions": {},
           "version": 2,
           "xAxis": {
            "labels": {
             "enabled": true
            },
            "type": "-"
           },
           "yAxis": [
            {
             "type": "-"
            },
            {
             "opposite": true,
             "type": "-"
            }
           ]
          }
         }
        ]
       },
       "datasetPreviewNameToCmdIdMap": {},
       "diffDeletes": [],
       "diffInserts": [],
       "displayType": "redashChart",
       "error": null,
       "errorDetails": null,
       "errorSummary": null,
       "errorTraceType": null,
       "finishTime": 0,
       "globalVars": {},
       "guid": "",
       "height": "auto",
       "hideCommandCode": false,
       "hideCommandResult": false,
       "iPythonMetadata": null,
       "inputWidgets": {},
       "isLockedInExamMode": false,
       "latestUser": "a user",
       "latestUserId": null,
       "listResultMetadata": null,
       "metadata": {},
       "nuid": "7d9009c9-0283-4ac9-a7c2-c136461972e9",
       "origId": 0,
       "parentHierarchy": [],
       "pivotAggregation": null,
       "pivotColumns": null,
       "position": 9.0,
       "resultDbfsErrorMessage": null,
       "resultDbfsStatus": "INLINED_IN_TREE",
       "results": null,
       "showCommandTitle": false,
       "startTime": 0,
       "state": "input",
       "streamStates": {},
       "subcommandOptions": {
        "queryPlan": {
         "groups": [
          {
           "column": "timestamp",
           "type": "column"
          }
         ],
         "selects": [
          {
           "column": "timestamp",
           "type": "column"
          },
          {
           "alias": "column_75fe649f390",
           "args": [
            {
             "column": "temperature_fahrenheit",
             "type": "column"
            }
           ],
           "function": "SUM",
           "type": "function"
          }
         ]
        }
       },
       "submitTime": 0,
       "subtype": "tableResultSubCmd.visualization",
       "tableResultIndex": 0,
       "tableResultSettingsMap": {},
       "useConsistentColors": false,
       "version": "CommandV1",
       "width": "auto",
       "workflows": null,
       "xColumns": null,
       "yColumns": null
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    " %sql\n",
    " SELECT * FROM transformed_iot_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d2ad3709-abda-4d21-8381-6509984eb0ca",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Stop the streaming query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fe177e8b-a4cc-4770-8b42-584271dccd30",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "query.stop()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 8546691222473153,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "DLT-Example-2",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
